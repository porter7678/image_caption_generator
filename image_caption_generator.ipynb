{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_caption_generator",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/porter7678/image_caption_generator/blob/master/image_caption_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTMqietwBylh",
        "colab_type": "text"
      },
      "source": [
        "###To Do:\n",
        "\n",
        "\n",
        "###Fix at the end:\n",
        " - Shuffle my dataloader\n",
        " - Size images back up\n",
        " - Get images to work even if theyâ€™re not square\n",
        " - I did 'drop_last' on my dataloaders, there is a chance I don't want to do that\n",
        "\n",
        "###Questions\n",
        " - What does pin_memory in the DataLoader do?\n",
        " - The research paper talks about a \"dictionary\" is that something I am actually supposed to include, or does that just refer to my collection of captions?\n",
        "\n",
        " ----------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saUiX2p428La",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install torch \n",
        "# !pip install torchvision\n",
        "# !pip install tqdm\n",
        "# !pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIPxNuxA4Bni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "assert torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmybwgB4qRT7",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6B-whcwDICG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = 'porter7678'\n",
        "if not 'KAGGLE_KEY' in os.environ:\n",
        "  os.environ['KAGGLE_KEY'] = input()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyvIBcScVojJ",
        "colab_type": "code",
        "outputId": "02740757-f18d-4a47-cae0-b29b9b10f343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "# ~70 secs\n",
        "!kaggle datasets download -d ming666/flicker8k-dataset\n",
        "!unzip -q flicker8k-dataset.zip\n",
        "\n",
        "# Discard extra directories\n",
        "! rm -rf flickr8k_dataset/\n",
        "! rm -rf flickr8k_text/\n",
        "! rm -rf sample_data/\n",
        "\n",
        "# Create Train and Valid directories\n",
        "os.mkdir('Flickr8k_Dataset/Train_Images')\n",
        "os.mkdir('Flickr8k_Dataset/Valid_Images')\n",
        "os.mkdir('Flickr8k_Dataset/Valid_Images/Flicker8k_Dataset_Valid')\n",
        "os.replace('Flickr8k_Dataset/Flicker8k_Dataset', 'Flickr8k_Dataset/Train_Images/Flicker8k_Dataset_Train')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading flicker8k-dataset.zip to /content\n",
            "100% 2.07G/2.08G [00:29<00:00, 97.1MB/s]\n",
            "100% 2.08G/2.08G [00:29<00:00, 74.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xhyb-SX6WMT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############ - DATATSET README - ################################################################\n",
        "# Flickr8k.token.txt - the raw captions of the Flickr8k Dataset,\n",
        "#       the first column is the ID of the caption which is \"image address # caption number\"\n",
        "# Flickr8k.lemma.txt - the lemmatized version of the above captions \n",
        "# Flickr_8k.trainImages.txt - The list of training images used in our experiments\n",
        "# Flickr_8k.devImages.txt - The list of development/validation images used in our experiments\n",
        "# Flickr_8k.testImages.txt - The list of test images used in our experiments\n",
        "#################################################################################################\n",
        "# 8091 images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeX3JYPZg6Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create list of images to move to validation folder\n",
        "valid_img_names = []\n",
        "file_names = ['Flickr8k_text/Flickr_8k.devImages.txt', 'Flickr8k_text/Flickr_8k.testImages.txt']\n",
        "for file_name in file_names:\n",
        "    with open(file_name, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            valid_img_names.append(line.strip())\n",
        "\n",
        "# Move validation images to validation folder\n",
        "for file_name in valid_img_names:\n",
        "    os.replace('Flickr8k_Dataset/Train_Images/Flicker8k_Dataset_Train/' + file_name, 'Flickr8k_Dataset/Valid_Images/Flicker8k_Dataset_Valid/' + file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6uQvLTLqdJj",
        "colab_type": "text"
      },
      "source": [
        "# Dataset Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM1wZ4Iygf57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_imgs(x, new_fig=True):\n",
        "    '''\n",
        "    Displays the image contained in a tensor.\n",
        "\n",
        "    Arguments:\n",
        "        x ((c,m,n) tensor): The image to be shown\n",
        "    '''\n",
        "    grid = vutils.make_grid(x.detach().cpu(), nrow=8, normalize=True, pad_value=0.3)\n",
        "    grid = grid.transpose(0,2).transpose(0,1) # channels as last dimension\n",
        "    if new_fig:\n",
        "        plt.figure()\n",
        "    plt.imshow(grid.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w59wWgyifXJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageCaptionDataset(Dataset):\n",
        "    '''\n",
        "    Dataset class containing images and captions\n",
        "\n",
        "    Attributes:\n",
        "        image_folder (ImageFolder Dataset): Images to be captioned (data)\n",
        "        caption_folder (Dataset): Captions associated with images for validation (labels)\n",
        "    '''\n",
        "    def __init__(self, train=True, img_size=128):\n",
        "        # Initialize with training images or validation images depending on train parameter\n",
        "        folder_prefix = 'Train' if train else 'Valid'\n",
        "        folder_path = 'Flickr8k_Dataset/' + folder_prefix + '_Images'\n",
        "        self.image_folder = datasets.ImageFolder(root=folder_path,\n",
        "                                                transform=transforms.Compose([\n",
        "                                                    transforms.Resize(img_size),\n",
        "                                                    transforms.CenterCrop(img_size),  # This is the line that is making images square\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                                                ]))\n",
        "        \n",
        "        # NOTE: There is a chance I need to find a way to stick this caption attribute in a Dataset class for the dataloader to work.\n",
        "        train_img_captions = []\n",
        "        valid_img_captions = []\n",
        "        curr_img_captions = []\n",
        "\n",
        "        with open('Flickr8k_text/Flickr8k.token.txt', 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        for i, line in enumerate(lines):\n",
        "            line = line.strip().split('\\t')\n",
        "            curr_img_captions.append(line[1])\n",
        "\n",
        "            # Each image has five captions, so start a new caption list each 5 iterations\n",
        "            if i % 5 == 4:\n",
        "                img_name = line[0][:-2]\n",
        "                if img_name in valid_img_names:\n",
        "                    valid_img_captions.append((img_name, curr_img_captions))\n",
        "                else:\n",
        "                    train_img_captions.append((img_name, curr_img_captions))\n",
        "                curr_img_captions = []\n",
        "\n",
        "        # Data cleaning: This is an extra caption in the dataset with no image\n",
        "        train_img_captions.pop(1010)\n",
        "\n",
        "        self.caption_folder = train_img_captions if train else valid_img_captions\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        img = self.image_folder[index]\n",
        "        captions = self.caption_folder[index]\n",
        "        return img[0], captions[1]\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.caption_folder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfi3JlCQAB4k",
        "colab_type": "code",
        "outputId": "22febdec-56dc-44fa-ba42-4ccf6b1a5251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "train_dataset = ImageCaptionDataset(train=True)\n",
        "valid_dataset = ImageCaptionDataset(train=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, \n",
        "                          batch_size=8, \n",
        "                          shuffle=False, \n",
        "                          pin_memory=True,\n",
        "                          drop_last=True)\n",
        "valid_loader = DataLoader(valid_dataset, \n",
        "                          batch_size=8, \n",
        "                          shuffle=False, \n",
        "                          pin_memory=True)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GBpqp-cSazC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}